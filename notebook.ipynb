{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmWH/0j5ZNFc1+xzqqN/sZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYDiJbVwJ5qV","executionInfo":{"status":"ok","timestamp":1724684738443,"user_tz":300,"elapsed":39628,"user":{"displayName":"Jeronimo Ledesma Patino","userId":"02626167002346710349"}},"outputId":"4b8889d8-a60a-4b45-dc48-0ee236da2971"},"outputs":[{"output_type":"stream","name":"stdout","text":["Pipeline(steps=[('tranformer',\n","                 ColumnTransformer(remainder='passthrough',\n","                                   transformers=[('ohe',\n","                                                  OneHotEncoder(dtype='int'),\n","                                                  ['thal'])])),\n","                ('selectkbest', SelectKBest(k=6)),\n","                ('estimator',\n","                 LogisticRegression(C=10, max_iter=10000, penalty='l1',\n","                                    solver='saga'))]):\n","--------------------------------------------------------------------------------\n","Balanced Accuracy: 0.6368 (0.8296)\n","         Accuracy: 0.6774 (0.8787)\n"]}],"source":["def load_data():\n","\n","    import pandas as pd\n","\n","    dataset = pd.read_csv(\"heart_disease.csv\")\n","    y = dataset.pop(\"target\")\n","    x = dataset.copy()\n","    x[\"thal\"] = x[\"thal\"].map(\n","        lambda x: \"normal\" if x not in [\"fixed\", \"fixed\", \"reversible\"] else x\n","    )\n","\n","    return x, y\n","\n","\n","x, y = load_data()\n","x\n","\n","\n","\n","def make_train_test_split(x, y):\n","\n","    from sklearn.model_selection import train_test_split\n","\n","    (x_train, x_test, y_train, y_test) = train_test_split(\n","        x,\n","        y,\n","        test_size=0.10,\n","        random_state=0,\n","    )\n","    return x_train, x_test, y_train, y_test\n","\n","def make_pipeline(estimator):\n","\n","    from sklearn.compose import ColumnTransformer\n","    from sklearn.feature_selection import SelectKBest, f_classif\n","    from sklearn.pipeline import Pipeline\n","    from sklearn.preprocessing import OneHotEncoder\n","\n","    transformer = ColumnTransformer(\n","        transformers=[\n","            (\"ohe\", OneHotEncoder(dtype=\"int\"), [\"thal\"]),\n","        ],\n","        remainder=\"passthrough\",\n","    )\n","\n","    selectkbest = SelectKBest(score_func=f_classif)\n","\n","    pipeline = Pipeline(\n","        steps=[\n","            (\"tranformer\", transformer),\n","            (\"selectkbest\", selectkbest),\n","            (\"estimator\", estimator),\n","        ],\n","        verbose=False,\n","    )\n","\n","    return pipeline\n","\n","\n","def make_grid_search(estimator, param_grid, cv=5):\n","\n","    from sklearn.model_selection import GridSearchCV\n","\n","    grid_search = GridSearchCV(\n","        estimator=estimator,\n","        param_grid=param_grid,\n","        cv=cv,\n","        scoring=\"balanced_accuracy\",\n","    )\n","\n","    return grid_search\n","\n","\n","def save_estimator(estimator):\n","\n","    import pickle\n","\n","    with open(\"estimator.pickle\", \"wb\") as file:\n","        pickle.dump(estimator, file)\n","\n","\n","def load_estimator():\n","\n","    import os\n","    import pickle\n","\n","    if not os.path.exists(\"estimator.pickle\"):\n","        return None\n","    with open(\"estimator.pickle\", \"rb\") as file:\n","        estimator = pickle.load(file)\n","\n","    return estimator\n","\n","\n","\n","\n","def train_estimator(estimator):\n","\n","    from sklearn.linear_model import LinearRegression\n","    from sklearn.metrics import mean_absolute_error\n","\n","    data, target = load_data()\n","\n","    x_train, x_test, y_train, y_test = make_train_test_split(\n","        x=data,\n","        y=target,\n","    )\n","\n","    estimator.fit(x_train, y_train)\n","\n","    best_estimator = load_estimator()\n","\n","    if best_estimator is not None:\n","\n","        saved_mae = mean_absolute_error(\n","            y_true=y_test, y_pred=best_estimator.predict(x_test)\n","        )\n","\n","        current_mae = mean_absolute_error(\n","            y_true=y_test, y_pred=estimator.predict(x_test)\n","        )\n","\n","        if saved_mae < current_mae:\n","            estimator = best_estimator\n","\n","    save_estimator(estimator)\n","\n","\n","\n","def train_logistic_regression():\n","\n","    from sklearn.linear_model import LogisticRegression\n","\n","    pipeline = make_pipeline(\n","        estimator=LogisticRegression(max_iter=10000, solver=\"saga\"),\n","    )\n","\n","    param_grid = {\n","        \"selectkbest__k\": range(1, 11),\n","        \"estimator__penalty\": [\"l1\", \"l2\"],\n","        \"estimator__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n","    }\n","\n","    estimator = make_grid_search(\n","        estimator=pipeline,\n","        param_grid=param_grid,\n","        cv=5,\n","    )\n","\n","    train_estimator(estimator)\n","\n","\n","train_logistic_regression()\n","\n","def eval_metrics(\n","    y_train_true,\n","    y_test_true,\n","    y_train_pred,\n","    y_test_pred,\n","):\n","\n","    from sklearn.metrics import accuracy_score, balanced_accuracy_score\n","\n","    accuracy_train = round(accuracy_score(y_train_true, y_train_pred), 4)\n","    accuracy_test = round(accuracy_score(y_test_true, y_test_pred), 4)\n","    balanced_accuracy_train = round(\n","        balanced_accuracy_score(y_train_true, y_train_pred), 4\n","    )\n","    balanced_accuracy_test = round(balanced_accuracy_score(y_test_true, y_test_pred), 4)\n","\n","    return (\n","        accuracy_train,\n","        accuracy_test,\n","        balanced_accuracy_train,\n","        balanced_accuracy_test,\n","    )\n","\n","\n","\n","def train_estimator(estimator):\n","\n","    from sklearn.linear_model import LinearRegression\n","    from sklearn.metrics import mean_absolute_error\n","\n","    data, target = load_data()\n","\n","    x_train, x_test, y_train, y_test = make_train_test_split(\n","        x=data,\n","        y=target,\n","    )\n","\n","    estimator.fit(x_train, y_train)\n","\n","    best_estimator = load_estimator()\n","\n","    if best_estimator is not None:\n","\n","        saved_mae = mean_absolute_error(\n","            y_true=y_test, y_pred=best_estimator.predict(x_test)\n","        )\n","\n","        current_mae = mean_absolute_error(\n","            y_true=y_test, y_pred=estimator.predict(x_test)\n","        )\n","\n","        if saved_mae < current_mae:\n","            estimator = best_estimator\n","\n","    save_estimator(estimator)\n","\n","def report(\n","    estimator,\n","    accuracy_train,\n","    accuracy_test,\n","    balanced_accuracy_train,\n","    balanced_accuracy_test,\n","):\n","\n","    print(estimator, \":\", sep=\"\")\n","    print(\"-\" * 80)\n","    print(f\"Balanced Accuracy: {balanced_accuracy_test} ({balanced_accuracy_train})\")\n","    print(f\"         Accuracy: {accuracy_test} ({accuracy_train})\")\n","\n","\n","\n","\n","\n","\n","\n","def check_estimator():\n","\n","    import pickle\n","\n","    import pandas as pd\n","    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","    data, target = load_data()\n","\n","    x_train, x_test, y_train_true, y_test_true = make_train_test_split(\n","        x=data,\n","        y=target,\n","    )\n","\n","    estimator = load_estimator()\n","\n","    y_train_pred = estimator.predict(x_train)\n","    y_test_pred = estimator.predict(x_test)\n","\n","    (\n","        accuracy_train,\n","        accuracy_test,\n","        balanced_accuracy_train,\n","        balanced_accuracy_test,\n","    ) = eval_metrics(\n","        y_train_true,\n","        y_test_true,\n","        y_train_pred,\n","        y_test_pred,\n","    )\n","\n","    report(\n","        estimator.best_estimator_,\n","        accuracy_train,\n","        accuracy_test,\n","        balanced_accuracy_train,\n","        balanced_accuracy_test,\n","    )\n","\n","\n","check_estimator()"]},{"cell_type":"code","source":["def train_mlp_classifier():\n","\n","    from sklearn.neural_network import MLPClassifier\n","\n","    pipeline = make_pipeline(\n","        estimator=MLPClassifier(max_iter=10000),\n","    )\n","\n","    param_grid = {\n","        \"selectkbest__k\": range(1, 11),\n","        \"estimator__hidden_layer_sizes\": [(h,) for h in range(1, 11)],\n","        \"estimator__learning_rate_init\": [0.0001, 0.001, 0.01, 0.1, 1.0],\n","    }\n","\n","    estimator = make_grid_search(\n","        estimator=pipeline,\n","        param_grid=param_grid,\n","        cv=5,\n","    )\n","\n","    train_estimator(estimator)\n","\n","\n","train_mlp_classifier()\n","check_estimator()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gctzz5W0OqOY","executionInfo":{"status":"ok","timestamp":1724685651947,"user_tz":300,"elapsed":777819,"user":{"displayName":"Jeronimo Ledesma Patino","userId":"02626167002346710349"}},"outputId":"1be60ecb-3f4a-4505-fe21-7d14977570cb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Pipeline(steps=[('tranformer',\n","                 ColumnTransformer(remainder='passthrough',\n","                                   transformers=[('ohe',\n","                                                  OneHotEncoder(dtype='int'),\n","                                                  ['thal'])])),\n","                ('selectkbest', SelectKBest(k=6)),\n","                ('estimator',\n","                 MLPClassifier(hidden_layer_sizes=(8,), learning_rate_init=0.1,\n","                               max_iter=10000))]):\n","--------------------------------------------------------------------------------\n","Balanced Accuracy: 0.6859 (0.8315)\n","         Accuracy: 0.7097 (0.8676)\n"]}]}]}